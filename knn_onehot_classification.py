# -*- coding: utf-8 -*-
"""KNN_OneHot_Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RSWHPu3hCCjU_nuJriRhDa5wndmW3GK9
"""

#pip install category_encoders

# Commented out IPython magic to ensure Python compatibility.
############################ For regression: f_regression, mutual_info_regression
############################ For classification: chi2, f_classif, mutual_info_classif
from sklearn.neighbors import NearestNeighbors,KNeighborsClassifier, KNeighborsRegressor, RadiusNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, confusion_matrix, accuracy_score, classification_report, mean_squared_error
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import category_encoders as ce
from imblearn.over_sampling import SMOTE, ADASYN
# %matplotlib inline
from sklearn.linear_model import RidgeCV
from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression, mutual_info_regression, mutual_info_classif, chi2
from time import time
from sklearn.model_selection import train_test_split

df = pd.read_csv('/content/sample_data/cancer.csv')

df.head(5)

df = df.drop(['id'], axis='columns')

#df['diagnosis'].replace(['M','B'], [1,0], inplace = True)
enc = ce.OneHotEncoder(use_cat_names=True)
df_enc = enc.fit_transform((df['diagnosis'])) 

df_enc

df = df.join(df_enc)
df = df.drop(['diagnosis'], axis='columns')
df

X = df.iloc[:, :23].values

X

YData = df[['diagnosis_M','diagnosis_B']]

YData = YData.values
YData

Y = df.iloc[:,23].values
X_train,X_test, Y_train, Y_test = train_test_split(X,YData, test_size=0.3, random_state=42)

print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)
print(type(X_train))
print(type(Y_train))

scaler = StandardScaler()
scaler.fit_transform(X_train)
scaler.transform(X_test)

knnCls = KNeighborsClassifier(weights='uniform',  n_neighbors=5)

knnCls.fit(X_train,Y_train)

Y_Pred_TEST = knnCls.predict(X_test)
print(Y_Pred_TEST)

Y_Pred_TRAIN = knnCls.predict(X_train)
print(Y_Pred_TRAIN)

res = knnCls.predict(X_test[50].reshape(1,-1))
res

acc =  accuracy_score(Y_test, Y_Pred_TEST)
acc2 = accuracy_score(Y_train, Y_Pred_TRAIN)
print("TEST DATA PRedict : ", acc)
print("TRAIN DATA PRedict : ",acc2)

#CLASSIFAICTION REPORT FOR Y TEST
classreport=  classification_report(Y_test, Y_Pred_TEST)
print(classreport)

#CLASSIFAICTION REPORT FOR Y TRAIN
classreport=  classification_report(Y_train, Y_Pred_TRAIN)
print(classreport)

# SCORE ACCURACY FOR TEST DATA
score = knnCls.score(X_test, Y_test)
score

# SCORE ACCURACY FOR TRAIN DATA
score = knnCls.score(X_train, Y_train)
score

# df['radius_mean'] = np.log(df['radius_mean'])
# df['texture_mean'] = np.log(df['texture_mean'])
# df['perimeter_mean'] = np.log(df['perimeter_mean'])
# df['area_mean'] = np.log(df['area_mean'])
# df['smoothness_mean'] = np.log(df['smoothness_mean'])
# df['compactness_mean'] = np.log(df['compactness_mean'])
# df['symmetry_mean'] = np.log(df['symmetry_mean'])
# df['fractal_dimension_mean'] = np.log(df['fractal_dimension_mean'])
# df['radius_se'] = np.log(df['radius_se'])
# df['texture_se'] = np.log(df['texture_se'])
# df['perimeter_se'] = np.log(df['perimeter_se'])
# df['smoothness_se'] = np.log(df['smoothness_se'])
# df['compactness_se'] = np.log(df['compactness_se'])
# df['symmetry_se'] = np.log(df['symmetry_se'])
# df['fractal_dimension_se'] = np.log(df['fractal_dimension_se'])
# df['radius_worst'] = np.log(df['radius_worst'])
# df['texture_worst'] = np.log(df['texture_worst'])
# df['perimeter_worst'] = np.log(df['perimeter_worst'])
# df['area_worst'] = np.log(df['area_worst'])
# df['smoothness_worst'] = np.log(df['smoothness_worst'])
# df['compactness_worst'] = np.log(df['compactness_worst'])
# df['symmetry_worst'] = np.log(df['symmetry_worst'])
# df['fractal_dimension_worst'] = np.log(df['fractal_dimension_worst'])